{
 "metadata": {
  "name": "",
  "signature": "sha256:c01dfbcceaff33ef878bc79c2ea604493892da36a5454f015d1b8dc07f217a96"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Can the best fitting NIH funding institute be predicted by keywords in a grant?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The NIH is made up of 27 institutes and centres (IC) that a principal investigator can submit a grant to. The NIH infact recommends that you suggest an IC that is most likely to be interested in your research. I wanted to see if I could predict the best fitting institute for R01s, which are major research grants.\n",
      "\n",
      "The feature set is made up of each of the keywords provided for each R01 grant and the categorical variable that I am going to predict is the funding institute or IC. \n",
      "\n",
      "So lets get started. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import re\n",
      "import urllib2\n",
      "from zipfile import ZipFile\n",
      "import csv\n",
      "import time\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pandas import DataFrame,Series\n",
      "import random\n",
      "\n",
      "from sklearn.svm  import LinearSVC\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next I am going to define a function that extracts unique keywords, the keywords for each grant and the IC that funded that grant."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# extract keywords for the last 4 years\n",
      "# the training set is data from 2011-2013\n",
      "# the test set is the data from the year 2014\n",
      "\n",
      "def getXYdata(R01data):\n",
      "    # function to extract keywords\n",
      "    \n",
      "    R01data=R01data.dropna(subset=['PROJECT_TERMS'])\n",
      "\n",
      "    keyWords=pd.DataFrame(R01data['PROJECT_TERMS'])\n",
      "    fundinIC=R01data[['ADMINISTERING_IC']]\n",
      "\n",
      "    #split and remove delimiters from keywords and convert to list\n",
      "    keyWords=keyWords.PROJECT_TERMS.apply(lambda x: x.lower()) #data type changes from dataframe to series\n",
      "    keyWords=keyWords.apply(lambda x: re.split(r'[;,\\s]\\s*',x)) # regex applied to each element in the list of list\n",
      "    keyWords=keyWords.tolist()\n",
      "\n",
      "    # concat all the words for each grant to make the feature vector for each \n",
      "    # so now all the keywords for each grant form one corpus with no delimiters.\n",
      "    # this makes generating the sparse matrix a lot easier\n",
      "    str= \" \"\n",
      "    grantKeyWords=list()\n",
      "    for x in range(len(keyWords)):\n",
      "        grantKeyWords.append(str.join(keyWords[x]))\n",
      "\n",
      "    ICs,garbage,Ydata=np.unique(fundinIC,True,True)\n",
      "\n",
      "    return(grantKeyWords,Ydata,keyWords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we iteratively call the function above for each fiscal year to create the training data. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#create the training set\n",
      "years=range(2011,2014)\n",
      "\n",
      "trainX=list()\n",
      "trainY=list()\n",
      "keyTrain=list()\n",
      "\n",
      "for year in years: \n",
      "        path='/Users/anasuyadas/nobackup/Dropbox/Dropbox/data/RePORTER_PRJ_C_FY%d.csv' %year\n",
      "        data=pd.read_csv(path,low_memory=False )\n",
      "        R01data= data.ix[data.ACTIVITY=='R01',:]\n",
      "        [grantKeyWords,Ydata,keyWords]= getXYdata(R01data)\n",
      "        \n",
      "        trainX.extend(grantKeyWords)# append each years data. Use extend so we dont end up with a list of lists\n",
      "        trainY.extend(Ydata)\n",
      "        keyTrain.extend(keyWords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our feature set now contains potentially redundant keyworkds across different years. We need to eliminate this redundancy and vectorize the feature set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#---------------------------------------------------------------------------------\n",
      "#first flatten the list of lists, extract unique words to make a vocabulary set \n",
      "# the vocabulary is based only on the training set \n",
      "keyVocab = [y for x in keyTrain for y in x]\n",
      "print \"Currently we have {0} features or words.\".format(len(keyVocab))\n",
      "keyVocab =np.unique(keyVocab)\n",
      "print \"However only {0} of these words are actually unique\".format(len(keyVocab))\n",
      "keyVocab=set(keyVocab)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Currently we have 10605461 features or words.\n",
        "However only 23528 of these words are actually unique"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Vectorizing the training data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The training data needs to be vectorized in order for us to train a classifier on it. Essentially the list of keywords for each grant can be represented as a sparse vector where 1 corresponds to a single occurence of that word. We also use the same vocabulary or feature set to to vectorize our testing data, in this example its data from fiscal year 2014. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make a sparse matrix of the training Xdata\n",
      "print \"Extracting features from the training dataset using a sparse vectorizer\"\n",
      "t0 = time()\n",
      "vec = CountVectorizer(vocabulary=keyVocab)\n",
      "trainXsparse=vec.fit_transform(xtrain)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# #---------------------------------------------------------------------------------\n",
      "year=2014\n",
      "path='/Users/anasuyadas/nobackup/Dropbox/Dropbox/data/RePORTER_PRJ_C_FY%d.csv' %year\n",
      "data=pd.read_csv(path,low_memory=False )\n",
      "R01data= data.ix[data.ACTIVITY=='R01',:].dropna(subset=['PROJECT_TERMS','STUDY_SECTION'])\n",
      "[grantTest,YTest,keyTest]= getXYdata(R01data)\n",
      "#vectorize the test data using the same vocabulary as the training data\n",
      "testSparse2014=vec.fit_transform(grantTest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training different classifiers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# #do the fitting\n",
      "clf = MultinomialNB()\n",
      "clf.fit(trainXsparse,ytrain)\n",
      "\n",
      "print \"\"clf.score(testXsparse,ytest) # 0.68632403081197124\n",
      "\n",
      "\n",
      "clf = BernoulliNB()\n",
      "clf.fit(trainXsparse,ytrain)\n",
      "clf.score(testXsparse,ytest) # 0.67622174516984468\n",
      "\n",
      "\n",
      "clf = LinearSVC()\n",
      "clf.fit(trainXsparse,ytrain)\n",
      "clf.score(testXsparse,ytest) # 0.94292208612198514\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}